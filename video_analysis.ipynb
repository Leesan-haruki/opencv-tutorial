{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df369ef8",
   "metadata": {},
   "source": [
    "# Video analysis\n",
    "## Meanshift and Camshift\n",
    "### Meanshift\n",
    "Meanshift decides the point such that the circle centered at that point has maximum pixel distribution. Iteratively the circle is moved untilã€€the distance between the centroid of distribution and the center of the circle is smaller than desired error. Usually, Histogram backprojected image and the initial target position is specified.\n",
    "\n",
    "### Meanshift in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b243ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91ace3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('inputs/slow.flv')\n",
    "\n",
    "# take the first frame of the video\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# initial window\n",
    "col, row, width, height = 300, 200, 100, 50\n",
    "track_window = (col, row, width, height)\n",
    "\n",
    "# set up the ROI for tracking\n",
    "roi = frame[row:row+height, col:col+width]\n",
    "hsv_roi = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "mask = cv2.inRange(hsv_roi, np.array((0., 60., 32.)), np.array((180., 255., 255.)))\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0, 180])\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# set up the termination criteria, either 10 iteration or move by at least 1 pt\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "        \n",
    "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "        col, row, width, height = track_window\n",
    "        \n",
    "        img2 = cv2.rectangle(frame, (col, row), (col+width, row+height), 255, 2)\n",
    "        cv2.startWindowThread()  # This line is not needed when you execute from terminal.\n",
    "        cv2.imshow('img2', img2)\n",
    "        \n",
    "        key = cv2.waitKey(60) & 0xff\n",
    "        if key == 27:\n",
    "            break\n",
    "        else:\n",
    "            cv2.imwrite(\"inputs/\" + chr(key) + \".jpg\", img2)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.waitKey(1)  # This line is not needed when you execute from terminal.\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)  # This line is not needed when you execute from terminal.\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc89f94",
   "metadata": {},
   "source": [
    "`cv2.meanShift()` has 3 arguments, back projection of the object histogram, initial search window, and criteria.\n",
    "\n",
    "### Camshift\n",
    "Above method has one problem that the window always has the same size whether the car is very far or very close to the camera. Window size and rotation should be adapted to the target.  \n",
    "Camshift resolves this problem. Once meanshift is applied, it updates the size of the window as $s = 2 \\times \\sqrt{\\frac{M_{00}}{256}}$. It also calculates the orientation of the best fitting ellipse to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aee0dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('inputs/slow.flv')\n",
    "\n",
    "# take first frame of the video\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# setup initial location of window\n",
    "col, row, width, height = 300, 200, 100, 50\n",
    "track_window = (col, row, width, height)\n",
    "\n",
    "# set up the ROI for tracking\n",
    "roi = frame[row:row+height, col:col+width]\n",
    "hsv_roi = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "mask = cv2.inRange(hsv_roi, np.array((0., 60., 32.)), np.array((180., 255., 255.)))\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0, 180])\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# set up the termination criteria, either 10 iteration or move by at least 1 pt\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "        \n",
    "        ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n",
    "        \n",
    "        # draw it on image\n",
    "        pts = cv2.boxPoints(ret)\n",
    "        pts = np.int0(pts)\n",
    "        \n",
    "        img2 = cv2.polylines(frame, [pts], True, 255, 2)\n",
    "        cv2.startWindowThread()  # This line is not needed when you execute from terminal.\n",
    "        cv2.imshow('img2', img2)\n",
    "        \n",
    "        key = cv2.waitKey(60) & 0xff\n",
    "        if key == 27:\n",
    "            break\n",
    "        else:\n",
    "            cv2.imwrite('inputs/' + chr(key) + \".jpg\", img2)\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cv2.waitKey(1)  # This line is not needed when you execute from terminal.\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)  # This line is not needed when you execute from terminal.\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5c0e05",
   "metadata": {},
   "source": [
    "## Optical flow\n",
    "Optical flow is 2D vector field where each vector is a displacement vector showing the movement of points from first frame to second.  \n",
    "Optical flow has many applications like structure from motion, video compression, video stabilization etc.  \n",
    "Optical flow works on several assumptions:\n",
    "1. The pixel intensities of an object do not change between consecutive frmaes.\n",
    "2. Neighbouring pixels have similar motion.\n",
    "\n",
    "Following equation is obtained:\n",
    "$$\n",
    "I(x, y, t) = I(x+dx, y+dy, t+dt)\n",
    "$$\n",
    "It is changed as:\n",
    "$$\n",
    "f_xu + f_yv + f_t = 0\n",
    "$$\n",
    "\n",
    "### Lucas-Kanade method\n",
    "Above equation can't be solved because one equation against two unknown variables $u, v$.  \n",
    "Lucas-Kanade method assumes that a 3 x 3 patch around the point have the same motion, and get 9 equations. A better solution is obtained with least square fit method.\n",
    "\n",
    "### Lucas-Kanade optical flow in OpenCV\n",
    "`cv2.calcOpticalFlowPyrLK(prevImg, nextImg, prevPts, nextPts,)` returns (nextPts, status, err)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82b818a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('inputs/slow.flv')\n",
    "\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict(maxCorners = 100, qualityLevel = 0.3, minDistance = 7, blockSize = 7)\n",
    "\n",
    "# params for lucas kanade optical flow\n",
    "lk_params = dict(winSize = (15, 15), maxLevel = 2, \n",
    "                               criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# create some random colors\n",
    "color = np.random.randint(0 ,255, (100, 3))\n",
    "\n",
    "# take the first frame and find corner in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "\n",
    "# create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "    \n",
    "    # select good points\n",
    "    if p1 is not None:\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "\n",
    "    # draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        a, b, c, d = map(int, (a, b, c, d))\n",
    "        mask = cv2.line(mask, (a, b), (c, d), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame, (a, b), 5, color[i].tolist(), -1)\n",
    "    img = cv2.add(frame, mask)\n",
    "    \n",
    "    cv2.startWindowThread()  # This line is not needed when you execute from terminal.\n",
    "    cv2.imshow('frame', img)\n",
    "    key = cv2.waitKey(30) & 0xff\n",
    "    if key == 27:\n",
    "        break\n",
    "        \n",
    "    # now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "cap.release()\n",
    "cv2.waitKey(1)  # This line is not needed when you execute from terminal.\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)  # This line is not needed when you execute from terminal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd96631",
   "metadata": {},
   "source": [
    "### Dense optical flow in OpenCV\n",
    "`cv2.calcOpticalFlowFarneback(prevImg, nextImg, flow, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags)` computes the optical flow for all the points in the frame while above method computes for corner. It returns 2-channel array with optical flow vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4af2152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('inputs/vtest.avi')\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[..., 1] = 255\n",
    "\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    \n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    cv2.startWindowThread()  # This line is not needed when you execute from terminal.\n",
    "    cv2.imshow('frame2', bgr)\n",
    "    key = cv2.waitKey(30) & 0xff\n",
    "    \n",
    "    if key == 27:\n",
    "        break\n",
    "    elif key == ord('s'):\n",
    "        cv2.imwrite('outputs/opticalfb.png', frame2)\n",
    "        cv2.imwrite('outputs/opticalhsv.png', bgr)\n",
    "    prvs = next\n",
    "\n",
    "cap.release()\n",
    "cv2.waitKey(1)  # This line is not needed when you execute from terminal.\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)  # This line is not needed when you execute from terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c18c1dd",
   "metadata": {},
   "source": [
    "## Background subtraction\n",
    "Background subtraction (BS) is a common technique form generating a foreground mask by using static cameras. Only dynamic objects such as people and car should be detected. There are few cases only the background image is obtained. It is more difficult if the shadow is on the image.\n",
    "### BackgroundSubtractorMOG\n",
    "This algorithm is based on gaussian mixture distribution. Pixels belonging background are modeled with 3 to 5 mixture distributions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1013ad67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('inputs/vtest.avi')\n",
    "\n",
    "fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    \n",
    "    fgmask = fgbg.apply(frame)\n",
    "    \n",
    "    cv2.startWindowThread()  # This line is not needed when you execute from terminal.\n",
    "    cv2.imshow('frame', fgmask)\n",
    "    key = cv2.waitKey(30) & 0xff\n",
    "    if key == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.waitKey(1)  # This line is not needed when you execute from terminal.\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)  # This line is not needed when you execute from terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36521cef",
   "metadata": {},
   "source": [
    "### BackgroundSubtractorMOG2\n",
    "This algorithm is also based on gaussian mixture distribution but it is important in that this algorithm chooses optimal numbers of mixture for each pixel.  \n",
    "There is an optional argument \"detectShadows\", which is True by default, whether detect the shadow or not. If set as True, it needs more computational time and shadows are depicted in gray. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "175df5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('inputs/vtest.avi')\n",
    "\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    \n",
    "    fgmask = fgbg.apply(frame)\n",
    "    \n",
    "    cv2.startWindowThread()  # This line is not needed when you execute from terminal.\n",
    "    cv2.imshow('frame', fgmask)\n",
    "    key = cv2.waitKey(30) & 0xff\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.waitKey(1)  # This line is not needed when you execute from terminal.\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)  # This line is not needed when you execute from terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d8970",
   "metadata": {},
   "source": [
    "### BackgroundSubtractorGMG\n",
    "This algorithm is combination of statistical background estimation method and region segmentation based on pixel-based Baysian estimation.  \n",
    "Initial some frames are used to build background model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04447965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('inputs/vtest.avi')\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "fgbg = cv2.bgsegm.createBackgroundSubtractorGMG()\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    \n",
    "    fgmask = fgbg.apply(frame)\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    cv2.startWindowThread()  # This line is not needed when you execute from terminal.\n",
    "    cv2.imshow('frmae', fgmask)\n",
    "    key = cv2.waitKey(30) & 0xff\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.waitKey(1)  # This line is not needed when you execute from terminal.\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)  # This line is not needed when you execute from terminal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
